"""
FastAPI application for Spell.
"""

import json
import logging
import base64
from typing import Any, AsyncGenerator

from fastapi import FastAPI, HTTPException, Request, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from sse_starlette.sse import EventSourceResponse
import asyncio

from src.graph import build_graph
from src.config import TEAM_MEMBERS
from contextlib import asynccontextmanager
from src.service.workflow_service import run_agent_workflow, initialize_graph, close_graph

# Configure logging
logger = logging.getLogger(__name__)

@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    Lifespan context manager for the FastAPI app.
    Handles startup and shutdown events.
    """
    logger.info("ğŸš€ Starting Spell API...")
    logger.info("Initializing application resources...")
    try:
        await initialize_graph()
        logger.info("âœ… Application initialized successfully.")
    except Exception as e:
        logger.critical(f"âŒ Application startup failed: {e}")
        raise e  # Ensure app crashes on startup if initialization fails
    yield
    logger.info("Cleaning up application resources...")
    await close_graph()
    logger.info("ğŸ‘‹ Application shutdown complete.")

# Create FastAPI app
app = FastAPI(
    title="Spell API",
    description="API for Spell LangGraph-based agent workflow",
    version="0.1.0",
    lifespan=lifespan,
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Allows all origins
    allow_credentials=True,
    allow_methods=["*"],  # Allows all methods
    allow_headers=["*"],  # Allows all headers
)

# Graph is now managed by service
# graph = build_graph()


class ContentItem(BaseModel):
    type: str = Field(..., description="The type of content (text, image, etc.)")
    text: str | None = Field(None, description="The text content if type is 'text'")
    image_url: str | None = Field(
        None, description="The image URL if type is 'image'"
    )


class ChatMessage(BaseModel):
    role: str = Field(
        ..., description="The role of the message sender (user or assistant)"
    )
    content: str | list[ContentItem] = Field(
        ...,
        description="The content of the message, either a string or a list of content items",
    )


class ChatRequest(BaseModel):
    messages: list[ChatMessage] = Field(..., description="The conversation history")
    debug: bool = Field(False, description="Whether to enable debug logging")
    deep_thinking_mode: bool = Field(
        False, description="Whether to enable deep thinking mode"
    )
    search_before_planning: bool = Field(
        False, description="Whether to search before planning"
    )
    thread_id: str | None = Field(None, description="The thread ID for persistence")
    pptx_template_base64: str | None = Field(
        None, 
        description="Base64-encoded PPTX template file for design context extraction"
    )


async def _extract_design_context(pptx_base64: str | None):
    """
    PPTXãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‹ã‚‰DesignContextã‚’æŠ½å‡ºã™ã‚‹ï¼ˆAIãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å¤–ã®äº‹å‰å‡¦ç†ï¼‰
    
    Args:
        pptx_base64: Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸPPTXãƒ•ã‚¡ã‚¤ãƒ«
        
    Returns:
        DesignContext or None
    """
    if not pptx_base64:
        return None
    
    try:
        from src.utils.template_analyzer import analyze_pptx_template
        
        # Base64ãƒ‡ã‚³ãƒ¼ãƒ‰
        pptx_bytes = base64.b64decode(pptx_base64)
        logger.info(f"Decoding PPTX template: {len(pptx_bytes)} bytes")
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè§£æï¼ˆäº‹å‰å‡¦ç†ï¼‰
        design_context = await analyze_pptx_template(
            pptx_bytes,
            filename="uploaded_template.pptx",
            upload_to_gcs_enabled=True
        )
        
        logger.info(
            f"DesignContext extracted: {len(design_context.layouts)} layouts, "
            f"{len(design_context.layout_image_bytes)} layout images"
        )
        return design_context
        
    except ImportError as e:
        logger.warning(f"PPTX template analysis not available: {e}")
        return None
    except Exception as e:
        logger.error(f"Failed to extract design context: {e}")
        return None


@app.post("/api/chat/stream")
async def chat_endpoint(request: ChatRequest, req: Request):
    """
    Chat endpoint for LangGraph invoke.

    Args:
        request: The chat request
        req: The FastAPI request object for connection state checking

    Returns:
        The streamed response
    """
    try:
        # Convert Pydantic models to dictionaries and normalize content format
        messages = []
        for msg in request.messages:
            message_dict = {"role": msg.role}

            # Handle both string content and list of content items
            if isinstance(msg.content, str):
                message_dict["content"] = msg.content
            else:
                # For content as a list, convert to the format expected by the workflow
                content_items = []
                for item in msg.content:
                    if item.type == "text" and item.text:
                        content_items.append({"type": "text", "text": item.text})
                    elif item.type == "image" and item.image_url:
                        content_items.append(
                            {"type": "image", "image_url": item.image_url}
                        )

                message_dict["content"] = content_items

            messages.append(message_dict)

        # [NEW] PPTXãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‹ã‚‰DesignContextã‚’æŠ½å‡ºï¼ˆäº‹å‰å‡¦ç†ï¼‰
        design_context = await _extract_design_context(request.pptx_template_base64)

        async def event_generator():
            try:
                async for event in run_agent_workflow(
                    messages,
                    request.debug,
                    request.deep_thinking_mode,
                    request.search_before_planning,
                    request.thread_id,
                    design_context=design_context,  # [NEW] è¿½åŠ 
                ):
                    # Check if client is still connected
                    if await req.is_disconnected():
                        logger.info("Client disconnected, stopping workflow")
                        break
                    yield {
                        "event": event["event"],
                        "data": json.dumps(event["data"], ensure_ascii=False),
                    }
            except asyncio.CancelledError:
                logger.info("Stream processing cancelled")
                raise

        return EventSourceResponse(
            event_generator(),
            media_type="text/event-stream",
            sep="\n",
        )
    except ValueError as e:
        logger.error(f"Invalid request data: {e}")
        raise HTTPException(status_code=400, detail=f"Invalid request: {str(e)}")
    except HTTPException as e:
        raise e  # Re-raise HTTPExceptions (like from helpers)
    except Exception as e:
        logger.error(f"Error in chat endpoint: {e}")
        raise HTTPException(status_code=500, detail=str(e))



@app.get("/health")
async def health_check():
    """Health check endpoint for Cloud Run."""
    return {"status": "ok"}


@app.post("/api/template/analyze")
async def analyze_template_endpoint(file: UploadFile = File(...)):
    """
    PPTXãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’è§£æã—ã¦DesignContextã‚’è¿”ã™ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    
    ã“ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¯ã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®äº‹å‰è§£æã«ä½¿ç”¨ã§ãã¾ã™ã€‚
    ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã§ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€è§£æçµæœã‚’
    ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦å¾Œç¶šã®chatãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ä½¿ç”¨ã§ãã¾ã™ã€‚
    
    Args:
        file: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸPPTXãƒ•ã‚¡ã‚¤ãƒ«
        
    Returns:
        è§£æçµæœï¼ˆJSONå½¢å¼ã®DesignContextï¼‰
    """
    if not file.filename or not file.filename.endswith(('.pptx', '.PPTX')):
        raise HTTPException(
            status_code=400, 
            detail="Invalid file type. Please upload a .pptx file."
        )
    
    try:
        from src.utils.template_analyzer import analyze_pptx_template
        
        # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        pptx_bytes = await file.read()
        logger.info(f"Received PPTX template: {file.filename} ({len(pptx_bytes)} bytes)")
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè§£æ
        design_context = await analyze_pptx_template(
            pptx_bytes,
            filename=file.filename,
            upload_to_gcs_enabled=True
        )
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆï¼ˆlayout_image_bytesã¯é™¤å¤–ã•ã‚Œã‚‹ï¼‰
        return {
            "success": True,
            "filename": file.filename,
            "design_context": design_context.model_dump(mode="json"),
            "summary": {
                "layouts_count": len(design_context.layouts),
                "layout_types": [l.layout_type for l in design_context.layouts],
                "color_scheme": {
                    "accent1": design_context.color_scheme.accent1,
                    "accent2": design_context.color_scheme.accent2,
                },
                "font_scheme": {
                    "major": design_context.font_scheme.major_latin,
                    "minor": design_context.font_scheme.minor_latin,
                }
            }
        }
        
    except ImportError as e:
        raise HTTPException(
            status_code=501,
            detail=f"PPTX template analysis dependencies not installed: {e}"
        )
    except Exception as e:
        logger.error(f"Error analyzing template: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to analyze template: {str(e)}"
        )


# --- [NEW] Features: History & In-painting ---

@app.get("/api/history")
async def get_history(uid: str | None = None):
    """
    Get conversation history for the sidebar.
    
    Args:
        uid: User ID (Firebase UID) to filter history. 
             Currently, without Auth middleware, this is trusted from client.
    
    Returns:
        List of session summaries.
    """
    # TODO: Implement actual DB query to 'checkpoints' table or similar.
    # Since we are using AsyncPostgresSaver, we need a way to list threads.
    # For now, returning a mock list to unblock Frontend development.
    
    mock_history = [
        {
            "id": "thread_demo_1",
            "title": "æ—¥æœ¬ã®çµŒæ¸ˆæˆé•·ãƒ—ãƒ¬ã‚¼ãƒ³",
            "timestamp": "2024-01-20T10:00:00Z",
            "summary": "AI generated slide deck about Japan's economy."
        },
        {
            "id": "thread_demo_2",
            "title": "US vs China Tech War",
            "timestamp": "2024-01-19T15:30:00Z",
            "summary": "Comparison of technology sectors."
        }
    ]
    return mock_history


class InpaintRequest(BaseModel):
    rect: dict[str, int] = Field(..., description="Selection rectangle {x, y, w, h}")
    prompt: str = Field(..., description="Modification instruction")


@app.post("/api/image/{image_id}/inpaint")
async def inpaint_image(image_id: str, request: InpaintRequest):
    """
    Apply In-painting / Deep Edit to a generated image.
    
    Args:
        image_id: ID (or URL/filename) of the target image.
        request: Inpaint parameters.
        
    Returns:
        JSON with new image information or confirmation.
    """
    logger.info(f"In-painting request for {image_id}: {request.prompt} at {request.rect}")
    
    # TODO: Integrate with backend agent/tool.
    # Options:
    # 1. Direct call to Vertex AI Imagen 2 Edit API.
    # 2. Trigger a LangGraph run with "Modify Slide X..." instruction.
    
    # For Phase 1, we acknowledge the request. 
    # Real implementation requires 'image_service' (TBD).
    
    return {
        "success": True,
        "message": "In-painting request received (Backend stub).",
        "new_image_url": None, # Should return new URL when implemented
        "original_image_id": image_id
    }

